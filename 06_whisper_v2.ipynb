{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUWTI9bPJH5USO0jDw5FBB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ynakayu/openai-api-sample-code-v2/blob/main/06_whisper_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-02-音声ファイルから文字起こしをしよう\n",
        "# !pip install openai==1.7.2\n",
        "!pip install openai==1.58.1"
      ],
      "metadata": {
        "id": "ol5pOTzlN82o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880aaaee-007a-4eb9-f6c4-8b821889dcdc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==1.58.1 in /usr/local/lib/python3.11/dist-packages (1.58.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.58.1) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.58.1) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.58.1) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.58.1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.58.1) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.58.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.58.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.58.1) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-02-音声ファイルから文字起こしをしよう\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "aA81FfBTORiF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-02-音声ファイルから文字起こしをしよう\n",
        "audio_file = open(\"./audio.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file\n",
        ")\n",
        "\n",
        "print(transcript.text)"
      ],
      "metadata": {
        "id": "wisVjR2MSBXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-03-レスポンスのフォーマットを設定しよう\n",
        "audio_file = open(\"./audio.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file,\n",
        "    # response_format = \"verbose_json\"\n",
        "    # response_format = \"text\"\n",
        "    # response_format = \"srt\"\n",
        "    response_format = \"vtt\"\n",
        ")\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "blCgqY6l-Aoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-04-サンプリング温度を設定しよう\n",
        "audio_file = open(\"./audio.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file,\n",
        "    response_format = \"text\",\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "CflJtgkwFaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-05-言語を明示的に設定しよう\n",
        "audio_file = open(\"./audio.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file,\n",
        "    response_format = \"text\",\n",
        "    language = \"ja\"\n",
        ")\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "CI_N0Om2Hg_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-06-プロンプト パラメーターを設定しよう\n",
        "audio_file = open(\"./audio.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file,\n",
        "    response_format = \"text\",\n",
        "    language = \"ja\",\n",
        "    prompt=\"中村祐太, OpenAI\"\n",
        ")\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "IaqQXiPKI3PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-07-音声ファイルから文字起こし後、翻訳も行おう\n",
        "audio_file = open(\"./audio.mp3\", \"rb\")\n",
        "transcript = client.audio.translations.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file,\n",
        "    # response_format = \"text\"\n",
        "    response_format = \"srt\"\n",
        ")\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "S0ZGaMWcKrw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 06-08-【アップデート情報】新モデルgpt-4o-transcribeを使おう\n",
        "audio_file = open(\"./audio.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    # model = \"gpt-4o-transcribe\",\n",
        "    model = \"gpt-4o-mini-transcribe\",\n",
        "    file = audio_file,\n",
        "    response_format = \"text\",\n",
        "    language = \"ja\"\n",
        ")\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_5yQu_ynKVI",
        "outputId": "3615fb57-6a18-4dee-c5eb-2c0aec9322e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "音声認識技術は、人間の声をテキストに変換する技術です。日常的にスマートスピーカーやスマートフォンの音声アシスタントで使用されています。この音声ファイルは中村悠太が提供するOpenAI API入門コースの個人学習用としてのみ利用できます。再配布はできません。\n",
            "\n"
          ]
        }
      ]
    }
  ]
}